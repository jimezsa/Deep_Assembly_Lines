<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3D Multi-Camera Scene Viewer</title>
    <style>
      @import url("https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500&family=Space+Grotesk:wght@300;400;500;600&display=swap");

      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      :root {
        --bg-primary: #0a0a0f;
        --bg-secondary: #12121a;
        --bg-tertiary: #1a1a25;
        --accent-cyan: #00d4ff;
        --accent-magenta: #ff00aa;
        --accent-green: #00ff88;
        --text-primary: #ffffff;
        --text-secondary: #8888aa;
        --text-muted: #555566;
        --border-color: #2a2a3a;
      }

      body {
        font-family: "Space Grotesk", sans-serif;
        background: var(--bg-primary);
        color: var(--text-primary);
        min-height: 100vh;
        overflow: hidden;
      }

      #canvas-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        z-index: 1;
      }

      canvas {
        display: block;
      }

      /* Header overlay */
      .header {
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        padding: 20px 30px;
        background: linear-gradient(
          180deg,
          rgba(10, 10, 15, 0.95) 0%,
          rgba(10, 10, 15, 0) 100%
        );
        z-index: 100;
        display: flex;
        justify-content: space-between;
        align-items: center;
        pointer-events: none;
      }

      .header > * {
        pointer-events: auto;
      }

      .logo {
        display: flex;
        align-items: center;
        gap: 12px;
      }

      .logo-icon {
        width: 36px;
        height: 36px;
        background: #000000;
        border-radius: 8px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-weight: 600;
        font-size: 14px;
      }

      .logo h1 {
        font-size: 1.1em;
        font-weight: 500;
        letter-spacing: -0.5px;
      }

      .logo h1 span {
        color: #ffffff;
      }

      .status-badge {
        display: flex;
        align-items: center;
        gap: 8px;
        background: var(--bg-tertiary);
        padding: 8px 16px;
        border-radius: 20px;
        border: 1px solid var(--border-color);
        font-size: 0.85em;
      }

      .status-dot {
        width: 8px;
        height: 8px;
        border-radius: 50%;
        background: var(--text-muted);
      }

      .status-dot.active {
        background: var(--accent-green);
        box-shadow: 0 0 10px var(--accent-green);
        animation: pulse 2s infinite;
      }

      @keyframes pulse {
        0%,
        100% {
          opacity: 1;
        }
        50% {
          opacity: 0.5;
        }
      }

      .panel-title {
        font-size: 0.75em;
        text-transform: uppercase;
        letter-spacing: 1.5px;
        color: #999999;
        margin-bottom: 15px;
        padding-bottom: 10px;
        border-bottom: 1px solid #333333;
      }

      .control-row {
        display: flex;
        align-items: center;
        justify-content: space-between;
        margin-bottom: 12px;
      }

      .control-row:last-child {
        margin-bottom: 0;
      }

      .control-label {
        font-size: 0.9em;
        color: #999999;
      }

      .control-value {
        font-family: "JetBrains Mono", monospace;
        font-size: 0.85em;
        color: #ffffff;
      }

      /* Camera list panel */
      .camera-panel {
        position: fixed;
        top: 80px;
        left: 20px;
        background: rgba(0, 0, 0, 0.95);
        border: 1px solid #333333;
        border-radius: 8px;
        padding: 20px;
        z-index: 100;
        max-width: 260px;
        max-height: calc(100vh - 120px);
        overflow-y: auto;
        backdrop-filter: blur(20px);
      }

      .camera-item {
        display: flex;
        align-items: center;
        gap: 12px;
        padding: 10px 12px;
        margin-bottom: 8px;
        background: rgba(255, 255, 255, 0.05);
        border-radius: 6px;
        border: 1px solid transparent;
        cursor: pointer;
        transition: all 0.2s ease;
      }

      .camera-item:hover {
        border-color: #555555;
        background: rgba(255, 255, 255, 0.1);
      }

      .camera-item.selected {
        border-color: #ffffff;
        background: rgba(255, 255, 255, 0.15);
      }

      .camera-color {
        width: 12px;
        height: 12px;
        border-radius: 3px;
      }

      .camera-info {
        flex: 1;
      }

      .camera-id {
        font-family: "JetBrains Mono", monospace;
        font-size: 0.85em;
        color: #ffffff;
      }

      .camera-number {
        font-size: 0.75em;
        color: #999999;
      }

      /* Buttons */
      .btn {
        padding: 10px 20px;
        font-size: 0.85em;
        font-weight: 500;
        border: 1px solid var(--border-color);
        border-radius: 6px;
        cursor: pointer;
        transition: all 0.2s ease;
        font-family: "Space Grotesk", sans-serif;
        text-transform: uppercase;
        letter-spacing: 0.5px;
      }

      .btn-primary {
        background: #000000;
        border: none;
        color: white;
      }

      .btn-primary:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
        background: #1a1a1a;
      }

      .btn-secondary {
        background: transparent;
        color: var(--text-secondary);
      }

      .btn-secondary:hover {
        background: var(--bg-tertiary);
        color: var(--text-primary);
      }

      .button-group {
        display: flex;
        gap: 10px;
        margin-top: 15px;
      }

      /* Loading overlay */
      .loading-overlay {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: var(--bg-primary);
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        z-index: 1000;
        transition: opacity 0.5s ease;
      }

      .loading-overlay.hidden {
        opacity: 0;
        pointer-events: none;
      }

      .loader {
        width: 60px;
        height: 60px;
        border: 3px solid var(--bg-tertiary);
        border-top-color: var(--accent-cyan);
        border-radius: 50%;
        animation: spin 1s linear infinite;
      }

      @keyframes spin {
        to {
          transform: rotate(360deg);
        }
      }

      .loading-text {
        margin-top: 20px;
        color: var(--text-secondary);
        font-size: 0.9em;
      }

      /* Instructions */
      .instructions {
        position: fixed;
        bottom: 20px;
        right: 20px;
        background: rgba(18, 18, 26, 0.95);
        border: 1px solid var(--border-color);
        border-radius: 12px;
        padding: 15px 20px;
        z-index: 100;
        backdrop-filter: blur(20px);
      }

      .instruction-item {
        display: flex;
        align-items: center;
        gap: 10px;
        margin-bottom: 8px;
        font-size: 0.8em;
        color: var(--text-secondary);
      }

      .instruction-item:last-child {
        margin-bottom: 0;
      }

      .key {
        background: var(--bg-tertiary);
        padding: 4px 8px;
        border-radius: 4px;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.9em;
        color: var(--text-primary);
        min-width: 60px;
        text-align: center;
      }
    </style>
  </head>
  <body>
    <!-- Loading overlay -->
    <div class="loading-overlay" id="loading">
      <div class="loader"></div>
      <div class="loading-text">Initializing 3D Scene...</div>
    </div>

    <!-- Three.js canvas -->
    <div id="canvas-container"></div>

    <!-- Header -->
    <div class="header">
      <div class="logo">
        <div class="logo-icon">3D</div>
        <h1>Multi-Camera <span>Scene Viewer</span></h1>
      </div>
      <div class="status-badge">
        <div class="status-dot" id="statusDot"></div>
        <span id="statusText">Connecting...</span>
      </div>
    </div>

    <!-- Camera panel with controls -->
    <div class="camera-panel">
      <div class="panel-title">Camera Views</div>
      <div class="control-row">
        <span class="control-label">Cameras</span>
        <span class="control-value" id="cameraCount">0</span>
      </div>
      <div
        class="button-group"
        style="
          margin-bottom: 15px;
          padding-bottom: 15px;
          border-bottom: 1px solid #333333;
        "
      >
        <button class="btn btn-primary" id="startBtn" style="width: 100%">
          Start Streams
        </button>
      </div>

      <!-- GLB Scene Controls -->
      <div class="panel-title" style="margin-top: 15px">GLB Scene Model</div>
      <div class="control-row">
        <label class="control-label" for="glbEnabled" style="cursor: pointer">
          <input
            type="checkbox"
            id="glbEnabled"
            checked
            style="margin-right: 8px; cursor: pointer"
          />
          Show GLB Scene
        </label>
        <span class="control-value" id="glbStatus" style="color: #00ff88"
          >Visible</span
        >
      </div>

      <!-- VGGT Controls -->
      <div class="panel-title" style="margin-top: 15px">VGGT Point Cloud</div>
      <div class="control-row">
        <label class="control-label" for="vggtEnabled" style="cursor: pointer">
          <input
            type="checkbox"
            id="vggtEnabled"
            style="margin-right: 8px; cursor: pointer"
          />
          Enable VGGT
        </label>
        <span class="control-value" id="vggtStatus" style="color: #888"
          >Off</span
        >
      </div>
      <div class="control-row">
        <span class="control-label">Interval (frames)</span>
        <select
          id="vggtInterval"
          style="
            background: var(--bg-tertiary);
            color: var(--text-primary);
            border: 1px solid var(--border-color);
            border-radius: 4px;
            padding: 4px 8px;
            font-size: 0.85em;
            cursor: pointer;
          "
        >
          <option value="1">1</option>
          <option value="2">2</option>
          <option value="3">3</option>
          <option value="4">4</option>
          <option value="5">5</option>
          <option value="10">10</option>
          <option value="20" selected>20</option>
          <option value="30">30</option>
          <option value="60">60</option>
        </select>
      </div>
      <div class="control-row">
        <span class="control-label">Points</span>
        <span class="control-value" id="vggtPoints">0</span>
      </div>

      <div
        style="
          border-top: 1px solid #333333;
          margin-top: 15px;
          padding-top: 15px;
        "
      >
        <div class="panel-title" style="margin-top: 0">Cameras</div>
      </div>
      <div id="cameraList"></div>
    </div>

    <!-- Three.js and OrbitControls from CDN -->
    <script type="importmap">
      {
        "imports": {
          "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
          "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
        }
      }
    </script>

    <script type="module">
      import * as THREE from "three";
      import { OrbitControls } from "three/addons/controls/OrbitControls.js";
      import { GLTFLoader } from "three/addons/loaders/GLTFLoader.js";
      import { OBJLoader } from "three/addons/loaders/OBJLoader.js";
      import { MTLLoader } from "three/addons/loaders/MTLLoader.js";

      // Color palette for cameras
      const CAMERA_COLORS = [
        0x00d4ff, // cyan
        0xff00aa, // magenta
        0x00ff88, // green
        0xffaa00, // orange
        0xff5555, // red
        0x55ff55, // lime
        0x5555ff, // blue
        0xffff55, // yellow
      ];

      // Scene state
      let scene, camera, renderer, controls;
      let cameraPlanes = {};
      let cameraFrustums = {};
      let calibrationData = {};
      let availableCameras = [];
      let streaming = false;
      let streamIntervals = {};

      // Multi-object model references for real-time pose updates
      let objectModels = {}; // object_name -> THREE.Object3D
      let objectCentroids = {}; // object_name -> THREE.Vector3 (centroid offset)
      let objectConfigs = {}; // object_name -> config from server (includes camera_id)
      let posePollingInterval = null;

      // First detection tracking - store first detected position for "case" object
      let firstDetectedPose = {}; // object_name -> {position: THREE.Vector3, quaternion: THREE.Quaternion}

      // Bounding box for case object
      let caseBoundingBox = null; // THREE.Mesh for transparent bounding box
      let caseBoundingBoxEdges = null; // THREE.LineSegments for box edges

      // Bounding box for tool object
      let toolBoundingBox = null; // THREE.Mesh for transparent bounding box
      let toolBoundingBoxEdges = null; // THREE.LineSegments for box edges

      // Distance line from tool to case
      let distanceLine = null; // THREE.Line connecting tool centroid to case vertex
      let distanceLabel = null; // THREE.Sprite showing distance in mm
      let caseBoundingBoxSize = null; // Store case bounding box size for vertex calculation

      // GLB scene model state
      let glbSceneModel = null; // THREE.Object3D for the loaded GLB scene
      let glbVisible = true;

      // VGGT point cloud state
      let vggtEnabled = false;
      let vggtPointCloud = null; // THREE.Points object
      let vggtPointCloudGroup = null; // Group to hold point cloud with transformation
      let vggtPollingInterval = null;
      let vggtLastPointCount = 0;
      const VGGT_ORIGIN_CAMERA = "135122071615"; // Reference camera for VGGT point cloud (first VGGT input camera)

      // DOM elements
      const container = document.getElementById("canvas-container");
      const loadingOverlay = document.getElementById("loading");
      const statusDot = document.getElementById("statusDot");
      const statusText = document.getElementById("statusText");
      const cameraCountEl = document.getElementById("cameraCount");
      const cameraListEl = document.getElementById("cameraList");
      const startBtn = document.getElementById("startBtn");

      // GLB DOM elements
      const glbEnabledCheckbox = document.getElementById("glbEnabled");
      const glbStatusEl = document.getElementById("glbStatus");

      // VGGT DOM elements
      const vggtEnabledCheckbox = document.getElementById("vggtEnabled");
      const vggtIntervalSelect = document.getElementById("vggtInterval");
      const vggtStatusEl = document.getElementById("vggtStatus");
      const vggtPointsEl = document.getElementById("vggtPoints");

      // Initialize Three.js scene
      function initScene() {
        // Scene
        scene = new THREE.Scene();
        scene.background = new THREE.Color(0xffffff);

        // Add fog for depth
        scene.fog = new THREE.Fog(0xffffff, 5, 20);

        // Camera
        camera = new THREE.PerspectiveCamera(
          60,
          window.innerWidth / window.innerHeight,
          0.1,
          100
        );
        // Position to see the multi-camera setup from above and side
        camera.position.set(1.5, 1.5, 2.5);
        camera.lookAt(0, 0, 0);

        // Renderer
        renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        container.appendChild(renderer.domElement);

        // Controls
        controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.05;
        controls.minDistance = 0.5;
        controls.maxDistance = 15;
        controls.target.set(0, 0, 0);

        // Lighting
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
        scene.add(ambientLight);

        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
        directionalLight.position.set(5, 10, 5);
        scene.add(directionalLight);

        // Grid helper at global coordinate origin (0,0,0)
        const gridHelper = new THREE.GridHelper(3, 15, 0x888888, 0xcccccc);
        gridHelper.position.set(-1, -1.3, -2); // Positioned at world origin
        scene.add(gridHelper);

        // Handle resize
        window.addEventListener("resize", onWindowResize);
      }

      function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      }

      // Load calibration data
      async function loadCalibration() {
        try {
          const response = await fetch("/api/calibration");
          calibrationData = await response.json();
          console.log("Calibration loaded:", Object.keys(calibrationData));
          return calibrationData;
        } catch (error) {
          console.error("Failed to load calibration:", error);
          return {};
        }
      }

      // Load GLB scene - origin is at camera 141722079467, 138422075916
      async function loadGLBScene() {
        const loader = new GLTFLoader();
        const glbPath = "videos/VGGT_demo/calib_david_glbscene_50.2.glb";

        //  "videos/VGGT_demo/calib_glbscene_24.2_All_maskbFalse_maskwFalse_camTrue_skyFalse_predDepthmap_and_Camera_Branch.glb";
        //"videos/VGGT_demo/calib_glbscene_48.1_All_maskbFalse_maskwFalse_camTrue_skyFalse_predDepthmap_and_Camera_Branch.glb";
        //"videos/VGGT_demo/glbscene_97.3_All_maskbFalse_maskwFalse_camTrue_skyFalse_predDepthmap_and_Camera_Branch.glb";
        //"videos/VGGT_demo/glbscene_48.1_All_maskbFalse_maskwFalse_camTrue_skyFalse_predDepthmap_and_Camera_Branch.glb";
        // "/videos/VGGT_demo/glbscene_50_All_maskbFalse_maskwFalse_camTrue_skyFalse_predDepthmap_and_Camera_Branch.glb";
        const glbOriginCameraId = "135122071615";

        return new Promise((resolve, reject) => {
          loader.load(
            glbPath,
            (gltf) => {
              console.log("GLB scene loaded successfully");
              const model = gltf.scene;

              // The GLB's origin is at camera 141722079467's viewpoint
              // We need to position the GLB at that camera's world position
              const calibration = calibrationData[glbOriginCameraId];
              if (calibration && calibration.extrinsics) {
                const ext = calibration.extrinsics;

                // Extract translation and rotation from camera extrinsics
                const t = [ext[0][3], ext[1][3], ext[2][3]];
                const R = [
                  [ext[0][0], ext[0][1], ext[0][2]],
                  [ext[1][0], ext[1][1], ext[1][2]],
                  [ext[2][0], ext[2][1], ext[2][2]],
                ];

                // Convert from OpenCV to Three.js coordinate system
                const position = new THREE.Vector3(t[0], -t[1], -t[2]);

                // Build rotation matrix in Three.js coordinates
                const rotMatrix = new THREE.Matrix4();
                rotMatrix.set(
                  R[0][0],
                  -R[0][1],
                  -R[0][2],
                  0,
                  -R[1][0],
                  R[1][1],
                  R[1][2],
                  0,
                  -R[2][0],
                  R[2][1],
                  R[2][2],
                  0,
                  0,
                  0,
                  0,
                  1
                );

                const quaternion = new THREE.Quaternion();
                quaternion.setFromRotationMatrix(rotMatrix);

                // Rotate 180 degrees around Y axis to face correct direction
                const flip180 = new THREE.Quaternion();
                flip180.setFromAxisAngle(new THREE.Vector3(0, 1, 0), Math.PI);
                quaternion.multiply(flip180);

                // Apply transformation to model
                model.position.copy(position);
                model.quaternion.copy(quaternion);

                // Scale if needed (uncomment if GLB is in mm instead of meters)
                model.scale.set(1.4, 1.4, 1.4);

                console.log(
                  `GLB model positioned at camera ${glbOriginCameraId}:`,
                  position.toArray().map((v) => v.toFixed(3))
                );
              } else {
                console.warn("Calibration not found for GLB origin camera");
                model.position.set(0, 0, 0);
              }

              scene.add(model);

              // Store reference for visibility control
              glbSceneModel = model;
              glbSceneModel.visible = glbVisible;

              console.log("GLB model added to scene");
              resolve(model);
            },
            (progress) => {
              const percent = (progress.loaded / progress.total) * 100;
              console.log(`Loading GLB: ${percent.toFixed(1)}%`);
            },
            (error) => {
              console.error("Error loading GLB:", error);
              reject(error);
            }
          );
        });
      }

      // Load DOPE objects configuration from server
      async function loadDopeObjectsConfig() {
        try {
          const response = await fetch("/api/objects/config");
          objectConfigs = await response.json();
          console.log(
            "DOPE objects config loaded:",
            Object.keys(objectConfigs)
          );
          return objectConfigs;
        } catch (error) {
          console.error("Failed to load DOPE objects config:", error);
          return {};
        }
      }

      // Load OBJ model with MTL material for a specific object
      async function loadOBJModel(objectName, objPath) {
        // Convert the obj_path from server format to URL path
        // obj_path: "data/scanned_objects/e-screw-driver/eScrewDriver.obj"
        // URL: "videos/scanned_objects/e-screw-driver/eScrewDriver.obj"
        const urlPath = objPath.replace("data/", "videos/");
        const lastSlashIndex = urlPath.lastIndexOf("/");
        const basePath = urlPath.substring(0, lastSlashIndex + 1);
        const objFileName = urlPath.substring(lastSlashIndex + 1);
        const mtlFileName = objFileName.replace(".obj", ".mtl");

        console.log(`[${objectName}] Starting OBJ model load...`);
        console.log(`[${objectName}] Base path:`, basePath);
        console.log(`[${objectName}] OBJ file:`, objFileName);
        console.log(`[${objectName}] MTL file:`, mtlFileName);

        return new Promise((resolve, reject) => {
          const mtlLoader = new MTLLoader();
          mtlLoader.setPath(basePath);

          mtlLoader.load(
            mtlFileName,
            (materials) => {
              materials.preload();
              console.log(`[${objectName}] MTL materials loaded`);

              const objLoader = new OBJLoader();
              objLoader.setMaterials(materials);

              objLoader.load(
                basePath + objFileName,
                (object) => {
                  console.log(`[${objectName}] OBJ model loaded successfully`);

                  // Apply scale
                  object.scale.set(1, 1, 1);

                  // Calculate bounding box to find centroid offset
                  const boundingBox = new THREE.Box3().setFromObject(object);
                  const center = new THREE.Vector3();
                  boundingBox.getCenter(center);

                  // Store the centroid offset (in model's local coordinates)
                  objectCentroids[objectName] = center.clone();
                  console.log(
                    `[${objectName}] Model centroid offset:`,
                    center.toArray().map((v) => v.toFixed(4))
                  );

                  // Initially hidden until we get a pose
                  object.visible = false;
                  object.position.set(0, 0, 0);
                  object.userData.objectName = objectName;

                  // Enable shadows if needed
                  object.traverse((child) => {
                    if (child instanceof THREE.Mesh) {
                      child.castShadow = true;
                      child.receiveShadow = true;
                    }
                  });

                  scene.add(object);

                  // Store reference for pose updates
                  objectModels[objectName] = object;

                  console.log(
                    `[${objectName}] OBJ model added to scene (hidden until DOPE detection)`
                  );
                  resolve(object);
                },
                (progress) => {
                  if (progress.total > 0) {
                    const percent = (progress.loaded / progress.total) * 100;
                    console.log(
                      `[${objectName}] Loading OBJ: ${percent.toFixed(1)}%`
                    );
                  }
                },
                (error) => {
                  console.error(
                    `[${objectName}] Error loading OBJ file:`,
                    basePath + objFileName
                  );
                  console.error(`[${objectName}] OBJ Error details:`, error);
                  reject(error);
                }
              );
            },
            (progress) => {
              // MTL loading progress
            },
            (error) => {
              console.error(
                `[${objectName}] Error loading MTL file:`,
                basePath + mtlFileName
              );
              console.error(`[${objectName}] MTL Error details:`, error);
              reject(error);
            }
          );
        });
      }

      // Create transparent bounding box for the case object
      function createCaseBoundingBox(caseModel) {
        // Calculate bounding box dimensions from the model
        const boundingBox = new THREE.Box3().setFromObject(caseModel);
        const size = new THREE.Vector3();
        boundingBox.getSize(size);

        // Store size for distance calculation
        caseBoundingBoxSize = size.clone();

        console.log(
          `[case] Bounding box size:`,
          size.toArray().map((v) => v.toFixed(4))
        );

        // Create transparent box mesh
        const boxGeometry = new THREE.BoxGeometry(size.x, size.y, size.z);
        const boxMaterial = new THREE.MeshBasicMaterial({
          color: 0x00d4ff, // Cyan/Blue color
          transparent: true,
          opacity: 0.15,
          side: THREE.DoubleSide,
          depthWrite: false,
        });

        caseBoundingBox = new THREE.Mesh(boxGeometry, boxMaterial);
        caseBoundingBox.visible = false; // Hidden until case is detected

        // Create edges for the bounding box
        const edgesGeometry = new THREE.EdgesGeometry(boxGeometry);
        const edgesMaterial = new THREE.LineBasicMaterial({
          color: 0x00d4ff,
          linewidth: 2,
          transparent: true,
          opacity: 0.8,
        });

        caseBoundingBoxEdges = new THREE.LineSegments(
          edgesGeometry,
          edgesMaterial
        );
        caseBoundingBox.add(caseBoundingBoxEdges);

        scene.add(caseBoundingBox);
        console.log("[case] Transparent bounding box created");
      }

      // Update case bounding box position to match the case model
      function updateCaseBoundingBox() {
        if (!caseBoundingBox || !objectModels["case"]) return;

        const caseModel = objectModels["case"];
        const centroid = objectCentroids["case"];

        if (caseModel.visible && centroid) {
          // Position bounding box at the case model's centroid position
          // The case model is offset so its centroid is at the detected pose
          // So the bounding box center should be at: model.position + rotated centroid
          const rotatedCentroid = centroid
            .clone()
            .applyQuaternion(caseModel.quaternion);
          caseBoundingBox.position
            .copy(caseModel.position)
            .add(rotatedCentroid);
          caseBoundingBox.quaternion.copy(caseModel.quaternion);
          caseBoundingBox.visible = true;

          // Update distance line to tool
          updateDistanceLine();
        }
      }

      // Create transparent bounding box for the tool object
      function createToolBoundingBox(toolModel) {
        // Calculate bounding box dimensions from the model
        const boundingBox = new THREE.Box3().setFromObject(toolModel);
        const size = new THREE.Vector3();
        boundingBox.getSize(size);

        console.log(
          `[tool] Bounding box size:`,
          size.toArray().map((v) => v.toFixed(4))
        );

        // Create transparent box mesh
        const boxGeometry = new THREE.BoxGeometry(size.x, size.y, size.z);
        const boxMaterial = new THREE.MeshBasicMaterial({
          color: 0x00ff88, // Green color
          transparent: true,
          opacity: 0.15,
          side: THREE.DoubleSide,
          depthWrite: false,
        });

        toolBoundingBox = new THREE.Mesh(boxGeometry, boxMaterial);
        toolBoundingBox.visible = false; // Hidden until tool is detected

        // Create edges for the bounding box
        const edgesGeometry = new THREE.EdgesGeometry(boxGeometry);
        const edgesMaterial = new THREE.LineBasicMaterial({
          color: 0x00ff88,
          linewidth: 2,
          transparent: true,
          opacity: 0.8,
        });

        toolBoundingBoxEdges = new THREE.LineSegments(
          edgesGeometry,
          edgesMaterial
        );
        toolBoundingBox.add(toolBoundingBoxEdges);

        scene.add(toolBoundingBox);
        console.log("[tool] Transparent bounding box created");
      }

      // Update tool bounding box position to match the tool model
      function updateToolBoundingBox() {
        if (!toolBoundingBox || !objectModels["tool"]) return;

        const toolModel = objectModels["tool"];
        const centroid = objectCentroids["tool"];

        if (toolModel.visible && centroid) {
          // Position bounding box at the tool model's centroid position
          const rotatedCentroid = centroid
            .clone()
            .applyQuaternion(toolModel.quaternion);
          toolBoundingBox.position
            .copy(toolModel.position)
            .add(rotatedCentroid);
          toolBoundingBox.quaternion.copy(toolModel.quaternion);
          toolBoundingBox.visible = true;

          // Update distance line to case
          updateDistanceLine();
        } else {
          toolBoundingBox.visible = false;
          // Hide distance line when tool is not visible
          if (distanceLine) distanceLine.visible = false;
          if (distanceLabel) distanceLabel.visible = false;
        }
      }

      // Create text sprite for distance label
      function createTextSprite(text, color = "#ffffff") {
        const canvas = document.createElement("canvas");
        const context = canvas.getContext("2d");
        canvas.width = 256;
        canvas.height = 64;

        // Clear canvas
        context.clearRect(0, 0, canvas.width, canvas.height);

        // Background
        context.fillStyle = "rgba(0, 0, 0, 0.7)";
        context.roundRect(0, 0, canvas.width, canvas.height, 8);
        context.fill();

        // Text
        context.font = "bold 32px JetBrains Mono, monospace";
        context.fillStyle = color;
        context.textAlign = "center";
        context.textBaseline = "middle";
        context.fillText(text, canvas.width / 2, canvas.height / 2);

        const texture = new THREE.CanvasTexture(canvas);
        texture.minFilter = THREE.LinearFilter;

        const material = new THREE.SpriteMaterial({
          map: texture,
          transparent: true,
          depthTest: false,
        });

        const sprite = new THREE.Sprite(material);
        sprite.scale.set(0.15, 0.0375, 1); // Adjust scale for readability

        return sprite;
      }

      // Update text on existing sprite
      function updateTextSprite(sprite, text, color = "#ffffff") {
        const canvas = document.createElement("canvas");
        const context = canvas.getContext("2d");
        canvas.width = 256;
        canvas.height = 64;

        // Clear canvas
        context.clearRect(0, 0, canvas.width, canvas.height);

        // Background
        context.fillStyle = "rgba(0, 0, 0, 0.7)";
        context.roundRect(0, 0, canvas.width, canvas.height, 8);
        context.fill();

        // Text
        context.font = "bold 32px JetBrains Mono, monospace";
        context.fillStyle = color;
        context.textAlign = "center";
        context.textBaseline = "middle";
        context.fillText(text, canvas.width / 2, canvas.height / 2);

        sprite.material.map.dispose();
        sprite.material.map = new THREE.CanvasTexture(canvas);
        sprite.material.map.minFilter = THREE.LinearFilter;
        sprite.material.needsUpdate = true;
      }

      // Initialize distance line and label
      function initDistanceLine() {
        // Create cylinder geometry for thick line (will be updated dynamically)
        // Start with a unit cylinder, will be scaled/positioned in updateDistanceLine
        const cylinderGeometry = new THREE.CylinderGeometry(0.004, 0.004, 1, 8); // 4mm radius
        const cylinderMaterial = new THREE.MeshBasicMaterial({
          color: 0xffaa00, // Orange color for visibility
          transparent: true,
          opacity: 0.9,
        });

        distanceLine = new THREE.Mesh(cylinderGeometry, cylinderMaterial);
        distanceLine.visible = false;
        scene.add(distanceLine);

        // Create distance label
        distanceLabel = createTextSprite("0 mm", "#ffaa00");
        distanceLabel.visible = false;
        scene.add(distanceLabel);

        console.log("[Distance] Line and label initialized");
      }

      // Get the 4 top vertices of the case bounding box in world coordinates
      function getCaseTopVertices() {
        if (
          !caseBoundingBox ||
          !caseBoundingBox.visible ||
          !caseBoundingBoxSize
        ) {
          return [];
        }

        const halfX = caseBoundingBoxSize.x / 2;
        const halfY = caseBoundingBoxSize.y / 2;
        const halfZ = caseBoundingBoxSize.z / 2;

        // Top vertices in local coordinates (Y is up)
        const localVertices = [
          new THREE.Vector3(-halfX, halfY, -halfZ),
          new THREE.Vector3(halfX, halfY, -halfZ),
          new THREE.Vector3(halfX, halfY, halfZ),
          new THREE.Vector3(-halfX, halfY, halfZ),
        ];

        // Transform to world coordinates
        const worldVertices = localVertices.map((v) => {
          const worldV = v.clone();
          worldV.applyQuaternion(caseBoundingBox.quaternion);
          worldV.add(caseBoundingBox.position);
          return worldV;
        });

        return worldVertices;
      }

      // Update distance line from tool tip (offset from centroid) to nearest case top vertex
      function updateDistanceLine() {
        if (!distanceLine || !distanceLabel) return;
        if (!toolBoundingBox || !toolBoundingBox.visible) {
          distanceLine.visible = false;
          distanceLabel.visible = false;
          return;
        }
        if (!caseBoundingBox || !caseBoundingBox.visible) {
          distanceLine.visible = false;
          distanceLabel.visible = false;
          return;
        }

        // Get tool centroid (center of tool bounding box)
        const toolCentroid = toolBoundingBox.position.clone();

        // Apply offset for e-screwdriver tip in tool's local coordinates
        // Offset: +8cm in Y, +10cm in Z (in meters)
        const tipOffset = new THREE.Vector3(0.11, 0.08, 0);
        // Rotate offset by tool's orientation to get world-space offset
        tipOffset.applyQuaternion(toolBoundingBox.quaternion);
        // Add offset to centroid to get tool tip position
        const toolTipPosition = toolCentroid.add(tipOffset);

        // Get case top vertices
        const caseTopVertices = getCaseTopVertices();
        if (caseTopVertices.length === 0) {
          distanceLine.visible = false;
          distanceLabel.visible = false;
          return;
        }

        // Find nearest top vertex to the tool tip
        let nearestVertex = caseTopVertices[0];
        let minDistance = toolTipPosition.distanceTo(nearestVertex);

        for (let i = 1; i < caseTopVertices.length; i++) {
          const dist = toolTipPosition.distanceTo(caseTopVertices[i]);
          if (dist < minDistance) {
            minDistance = dist;
            nearestVertex = caseTopVertices[i];
          }
        }

        // Update cylinder position and orientation
        // Position at midpoint between the two points
        const midpoint = new THREE.Vector3()
          .addVectors(toolTipPosition, nearestVertex)
          .multiplyScalar(0.5);
        distanceLine.position.copy(midpoint);

        // Scale cylinder height to match distance
        distanceLine.scale.set(1, minDistance, 1);

        // Orient cylinder to point from toolTip to nearestVertex
        // Cylinder's default orientation is along Y axis
        const direction = new THREE.Vector3()
          .subVectors(nearestVertex, toolTipPosition)
          .normalize();
        const quaternion = new THREE.Quaternion();
        quaternion.setFromUnitVectors(new THREE.Vector3(0, 1, 0), direction);
        distanceLine.quaternion.copy(quaternion);

        distanceLine.visible = true;

        // Update label position (midpoint of line, slightly offset)
        const labelPos = midpoint.clone();
        labelPos.y += 0.02; // Slight offset above the line
        distanceLabel.position.copy(labelPos);

        // Update label text (convert meters to mm)
        const distanceMM = Math.round(minDistance * 1000);
        updateTextSprite(distanceLabel, `${distanceMM} mm`, "#ffaa00");
        distanceLabel.visible = true;
        
        // Send distance to backend (in cm)
        const distanceCM = minDistance * 100;
        sendDistanceToBackend(distanceCM);
      }
      
      // Throttle for sending distance to backend
      let lastDistanceSendTime = 0;
      const DISTANCE_SEND_INTERVAL = 100; // Send every 100ms max
      
      // Send distance to backend
      async function sendDistanceToBackend(distanceCM) {
        const now = Date.now();
        if (now - lastDistanceSendTime < DISTANCE_SEND_INTERVAL) {
          return; // Throttle requests
        }
        lastDistanceSendTime = now;
        
        try {
          await fetch('/api/distance/tool-case', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ distance_cm: distanceCM })
          });
        } catch (error) {
          // Silently handle errors to avoid console spam
        }
      }

      // Load all configured DOPE objects
      async function loadAllDopeObjects() {
        await loadDopeObjectsConfig();

        const loadPromises = [];
        for (const [objectName, config] of Object.entries(objectConfigs)) {
          if (config.obj_path) {
            loadPromises.push(
              loadOBJModel(objectName, config.obj_path).catch((error) => {
                console.warn(
                  `[${objectName}] Failed to load model, continuing:`,
                  error
                );
                return null;
              })
            );
          }
        }

        await Promise.all(loadPromises);
        console.log(`Loaded ${Object.keys(objectModels).length} object models`);

        // Create bounding box for case object if loaded
        if (objectModels["case"]) {
          createCaseBoundingBox(objectModels["case"]);
        }

        // Create bounding box for tool object if loaded
        if (objectModels["tool"]) {
          createToolBoundingBox(objectModels["tool"]);
        }

        // Initialize distance line between tool and case
        initDistanceLine();
      }

      // Fetch and update poses for all detected objects
      async function updateObjectPoses() {
        if (Object.keys(objectModels).length === 0) return;

        try {
          const response = await fetch("/api/objects/poses");
          const posesData = await response.json();

          let detectedCount = 0;
          let totalObjects = Object.keys(objectModels).length;
          let firstDetectedPos = null;

          // Update each object
          for (const [objectName, poseData] of Object.entries(posesData)) {
            const model = objectModels[objectName];
            const centroid = objectCentroids[objectName];
            const config = objectConfigs[objectName];

            if (!model || !centroid || !config) continue;

            // For "case" object, use first detected position if already stored
            if (objectName === "case" && firstDetectedPose[objectName]) {
              model.position.copy(firstDetectedPose[objectName].position);
              model.quaternion.copy(firstDetectedPose[objectName].quaternion);
              model.visible = true;
              updateCaseBoundingBox();
              detectedCount++;
              continue;
            }

            if (poseData && poseData.detected) {
              // Get the camera calibration for this object's assigned camera
              const cameraId = poseData.camera_id || config.camera_id;
              const camCalib = calibrationData[cameraId];
              if (!camCalib || !camCalib.extrinsics) {
                console.warn(
                  `No calibration for camera ${cameraId} (object: ${objectName})`
                );
                continue;
              }

              detectedCount++;

              // Extract camera extrinsics (camera to world transform)
              const ext = camCalib.extrinsics;
              const camR = new THREE.Matrix4();
              camR.set(
                ext[0][0],
                -ext[0][1],
                -ext[0][2],
                0,
                -ext[1][0],
                ext[1][1],
                ext[1][2],
                0,
                -ext[2][0],
                ext[2][1],
                ext[2][2],
                0,
                0,
                0,
                0,
                1
              );
              const camPos = new THREE.Vector3(
                ext[0][3],
                -ext[1][3],
                -ext[2][3]
              );
              const camQuat = new THREE.Quaternion().setFromRotationMatrix(
                camR
              );

              // Object pose from DOPE (in camera coordinates)
              const objLocation = poseData.location; // [x, y, z] in meters
              const objQuaternion = poseData.quaternion; // [x, y, z, w]

              // Convert object position from camera to world coordinates
              // In OpenCV camera: X-right, Y-down, Z-forward
              // In Three.js: X-right, Y-up, Z-backward
              const objLocalPos = new THREE.Vector3(
                objLocation[0],
                -objLocation[1], // Flip Y
                -objLocation[2] // Flip Z
              );

              // Transform to world coordinates
              objLocalPos.applyQuaternion(camQuat);
              const worldPos = objLocalPos.add(camPos);

              // Store first detected position for UI
              if (!firstDetectedPos) {
                firstDetectedPos = worldPos.clone();
              }

              // Convert object rotation from OpenCV to Three.js
              // Quaternion from DOPE is in camera frame
              const objQuat = new THREE.Quaternion(
                objQuaternion[0],
                -objQuaternion[1], // Flip Y
                -objQuaternion[2], // Flip Z
                objQuaternion[3]
              );

              // Combine with camera rotation
              const worldQuat = camQuat.clone().multiply(objQuat);

              // Flip the object 180 degrees around Y axis (in XZ plane)
              const flipY = new THREE.Quaternion();
              flipY.setFromAxisAngle(new THREE.Vector3(0, 0, 1), Math.PI);
              const flipZ = new THREE.Quaternion();
              flipZ.setFromAxisAngle(new THREE.Vector3(0, 1, 0), Math.PI);
              const finalQuat = worldQuat
                .clone()
                .multiply(flipY)
                .multiply(flipZ);

              // Apply pose to model's centroid (not origin)
              // Rotate the centroid offset by the final rotation (including flip)
              const rotatedCentroid = centroid
                .clone()
                .applyQuaternion(finalQuat);

              // Offset position so centroid is at the detected pose
              const modelPos = worldPos.clone().sub(rotatedCentroid);

              // Apply tool-specific offset: move -10cm in global z-axis
              if (objectName === "tool") {
                modelPos.y -= 0.08; // -10cm in meters
              }
              if (objectName === "case") {
                modelPos.z -= 0.04; // -4cm in meters
                modelPos.x += 0.05; // 5cm in meters
              }
              // Store first detected pose for "case" object
              if (objectName === "case" && !firstDetectedPose[objectName]) {
                firstDetectedPose[objectName] = {
                  position: modelPos.clone(),
                  quaternion: finalQuat.clone(),
                };
                console.log(
                  `[${objectName}] First detection stored at:`,
                  modelPos.toArray().map((v) => v.toFixed(3))
                );
              }

              //const modelPos = worldPos.clone();
              // Apply to model - always visible once detected
              model.position.copy(modelPos);
              model.quaternion.copy(finalQuat);
              model.visible = true;

              // Update bounding box for case object
              if (objectName === "case") {
                updateCaseBoundingBox();
              }

              // Update bounding box for tool object
              if (objectName === "tool") {
                updateToolBoundingBox();
              }
            }
          }

          // Update status indicators
          if (detectedCount > 0) {
            statusDot.classList.add("active");
            statusText.textContent = `${detectedCount}/${totalObjects} Objects`;
          } else {
            if (!streaming) {
              statusText.textContent = "Ready";
            } else {
              statusText.textContent = "Streaming";
            }
          }
        } catch (error) {
          // Silently handle errors to avoid console spam
        }
      }

      // Start polling for object pose updates
      function startPosePolling() {
        if (posePollingInterval) return;
        posePollingInterval = setInterval(updateObjectPoses, 100); // Poll every 100ms
        console.log("[Pose] Started polling for object poses");
      }

      // Stop polling for object pose updates
      function stopPosePolling() {
        if (posePollingInterval) {
          clearInterval(posePollingInterval);
          posePollingInterval = null;
          console.log("[Pose] Stopped polling for object poses");
        }
        // Keep models visible at last known position (don't hide them)
        // Note: firstDetectedPose is NOT reset here so case stays at its position
      }

      // ==========================================================
      // VGGT Point Cloud Functions
      // ==========================================================

      // Initialize VGGT point cloud visualization
      function initVGGTPointCloud() {
        // Create a group to hold the point cloud with transformation
        vggtPointCloudGroup = new THREE.Group();

        // Create initial empty point cloud
        const geometry = new THREE.BufferGeometry();
        geometry.setAttribute(
          "position",
          new THREE.Float32BufferAttribute([], 3)
        );
        geometry.setAttribute("color", new THREE.Float32BufferAttribute([], 3));

        const material = new THREE.PointsMaterial({
          size: 0.01,
          vertexColors: true,
          sizeAttenuation: true,
        });

        vggtPointCloud = new THREE.Points(geometry, material);
        vggtPointCloudGroup.add(vggtPointCloud);
        vggtPointCloudGroup.visible = false;

        // Scale the point cloud to match the GLB scene scale
        vggtPointCloudGroup.scale.set(1.2, 1.2, 1.2);

        // Position the point cloud group relative to the reference camera (135122071615)
        updateVGGTPointCloudOrigin(VGGT_ORIGIN_CAMERA);

        scene.add(vggtPointCloudGroup);
        console.log("[VGGT] Point cloud initialized");
      }

      // Update VGGT point cloud position based on selected origin camera
      // This transforms points from VGGT's coordinate system (first camera at origin)
      // to the world coordinate system used by the calibrated cameras
      function updateVGGTPointCloudOrigin(cameraId) {
        if (!vggtPointCloudGroup) return;

        const calibration = calibrationData[cameraId];
        if (calibration && calibration.extrinsics) {
          const ext = calibration.extrinsics;

          // The extrinsics are camera-to-world transforms (4x4 matrix)
          // They define where the camera is in world coordinates
          //
          // VGGT outputs points in its own coordinate system where the first
          // input camera is at the origin. To align with our world coordinate
          // system, we apply the selected camera's extrinsics.
          //
          // For best alignment, select the first VGGT input camera (135122071615)

          // Extract translation and rotation from camera extrinsics
          const t = [ext[0][3], ext[1][3], ext[2][3]];
          const R = [
            [ext[0][0], ext[0][1], ext[0][2]],
            [ext[1][0], ext[1][1], ext[1][2]],
            [ext[2][0], ext[2][1], ext[2][2]],
          ];

          // Convert camera position from OpenCV to Three.js coordinate system
          // OpenCV: X-right, Y-down, Z-forward
          // Three.js: X-right, Y-up, Z-backward
          const position = new THREE.Vector3(t[0], -t[1], -t[2]);

          // Convert rotation matrix from OpenCV to Three.js coordinates
          // The conversion flips the Y and Z components of the rotation
          const rotMatrix = new THREE.Matrix4();
          rotMatrix.set(
            R[0][0],
            -R[0][1],
            -R[0][2],
            0,
            -R[1][0],
            R[1][1],
            R[1][2],
            0,
            -R[2][0],
            R[2][1],
            R[2][2],
            0,
            0,
            0,
            0,
            1
          );

          const quaternion = new THREE.Quaternion();
          quaternion.setFromRotationMatrix(rotMatrix);

          // Apply transformation to the group
          // This positions the VGGT point cloud in world coordinates
          vggtPointCloudGroup.position.copy(position);
          vggtPointCloudGroup.quaternion.copy(quaternion);

          console.log(
            `[VGGT] Point cloud origin set to camera ${cameraId}:`,
            position.toArray().map((v) => v.toFixed(3))
          );
        } else {
          console.warn(
            `[VGGT] No calibration found for camera ${cameraId}, keeping current position`
          );
        }
      }

      // VGGT optimization: track last version to avoid redundant updates
      let vggtLastVersion = -1; // Start at -1 to ensure first fetch always happens
      let vggtUpdateInProgress = false;

      // Pre-allocated buffers for point cloud (reused across updates)
      let vggtPositionBuffer = null;
      let vggtColorBuffer = null;
      let vggtBufferSize = 0;

      // Update VGGT point cloud from server data (OPTIMIZED with binary transfer)
      async function updateVGGTPointCloud() {
        if (!vggtEnabled || vggtUpdateInProgress) {
          return;
        }

        vggtUpdateInProgress = true;

        try {
          // Fetch binary data directly (skip version check for simplicity and reliability)
          const response = await fetch("/api/vggt/pointcloud/binary");

          if (!response.ok) {
            console.error(
              "[VGGT] Fetch failed:",
              response.status,
              response.statusText
            );
            vggtUpdateInProgress = false;
            return;
          }

          const buffer = await response.arrayBuffer();
          console.log("[VGGT] Received buffer:", buffer.byteLength, "bytes");

          // Check minimum size for header
          if (buffer.byteLength < 12) {
            console.log("[VGGT] Buffer too small, skipping");
            vggtUpdateInProgress = false;
            return;
          }

          // Parse header (12 bytes: num_points, version, inference_time_ms)
          const header = new Uint32Array(buffer, 0, 3);
          const numPoints = header[0];
          const version = header[1];
          const inferenceTimeMs = header[2];

          // Skip if no points or same version
          if (numPoints === 0) {
            vggtStatusEl.textContent = "Waiting...";
            vggtStatusEl.style.color = "#ffaa00";
            vggtUpdateInProgress = false;
            return;
          }

          // Skip if version hasn't changed
          if (version === vggtLastVersion) {
            vggtUpdateInProgress = false;
            return;
          }

          // Verify buffer size
          const expectedSize = 12 + numPoints * 3 * 4 + numPoints * 3;
          if (buffer.byteLength < expectedSize) {
            console.error(
              "[VGGT] Buffer too small:",
              buffer.byteLength,
              "expected:",
              expectedSize
            );
            vggtUpdateInProgress = false;
            return;
          }

          // Parse points (float32 x, y, z for each point)
          const pointsOffset = 12; // After header
          const pointsBytes = numPoints * 3 * 4; // 3 floats * 4 bytes each
          const rawPoints = new Float32Array(
            buffer,
            pointsOffset,
            numPoints * 3
          );

          // Parse colors (uint8 r, g, b for each point)
          const colorsOffset = pointsOffset + pointsBytes;
          const rawColors = new Uint8Array(buffer, colorsOffset, numPoints * 3);

          // Allocate output buffers
          const positions = new Float32Array(numPoints * 3);
          const colors = new Float32Array(numPoints * 3);

          // Convert coordinates: VGGT (X-right, Y-down, Z-forward) -> Three.js (X-right, Y-up, Z-backward)
          // And convert colors to 0-1 range
          for (let i = 0; i < numPoints; i++) {
            const i3 = i * 3;
            positions[i3] = rawPoints[i3]; // X stays
            positions[i3 + 1] = -rawPoints[i3 + 1]; // Y negated
            positions[i3 + 2] = -rawPoints[i3 + 2]; // Z negated

            colors[i3] = rawColors[i3] / 255;
            colors[i3 + 1] = rawColors[i3 + 1] / 255;
            colors[i3 + 2] = rawColors[i3 + 2] / 255;
          }

          // Update geometry
          const geometry = vggtPointCloud.geometry;

          geometry.setAttribute(
            "position",
            new THREE.BufferAttribute(positions, 3)
          );
          geometry.setAttribute("color", new THREE.BufferAttribute(colors, 3));

          geometry.computeBoundingSphere();
          vggtPointCloudGroup.visible = true;

          // Update UI
          vggtPointsEl.textContent = numPoints.toLocaleString();
          vggtStatusEl.textContent = `${numPoints.toLocaleString()} pts (${inferenceTimeMs}ms)`;
          vggtStatusEl.style.color = "#00ff88";
          vggtLastPointCount = numPoints;
          vggtLastVersion = version;

          console.log(
            `[VGGT] Updated: ${numPoints} points, v${version}, ${inferenceTimeMs}ms`
          );
        } catch (error) {
          console.error("[VGGT] Update error:", error);
        }

        vggtUpdateInProgress = false;
      }

      // Start polling for VGGT point cloud
      function startVGGTPolling() {
        if (vggtPollingInterval) return;
        // Poll every 500ms for reliability
        vggtPollingInterval = setInterval(updateVGGTPointCloud, 500);
        console.log(
          "[VGGT] Started polling for point cloud (binary mode, 500ms interval)"
        );
        // Also do an immediate update
        updateVGGTPointCloud();
      }

      // Stop polling for VGGT point cloud
      function stopVGGTPolling() {
        if (vggtPollingInterval) {
          clearInterval(vggtPollingInterval);
          vggtPollingInterval = null;
          console.log("[VGGT] Stopped polling for point cloud");
        }
      }

      // Toggle VGGT enabled state
      async function setVGGTEnabled(enabled) {
        try {
          const response = await fetch("/api/vggt/enable", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ enabled }),
          });
          const result = await response.json();

          if (result.success) {
            vggtEnabled = enabled;
            vggtEnabledCheckbox.checked = enabled;

            if (enabled) {
              vggtStatusEl.textContent = "Starting...";
              vggtStatusEl.style.color = "#ffaa00";
              if (streaming) {
                startVGGTPolling();
              }
            } else {
              vggtStatusEl.textContent = "Off";
              vggtStatusEl.style.color = "#888";
              stopVGGTPolling();
              if (vggtPointCloudGroup) {
                vggtPointCloudGroup.visible = false;
              }
            }

            console.log(`[VGGT] ${enabled ? "Enabled" : "Disabled"}`);
          }
        } catch (error) {
          console.error("[VGGT] Failed to toggle:", error);
        }
      }

      // Set VGGT inference interval
      async function setVGGTInterval(interval) {
        try {
          const response = await fetch("/api/vggt/interval", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ interval: parseInt(interval) }),
          });
          const result = await response.json();

          if (result.success) {
            console.log(`[VGGT] Interval set to ${interval} frames`);
          }
        } catch (error) {
          console.error("[VGGT] Failed to set interval:", error);
        }
      }

      // Load VGGT status from server
      async function loadVGGTStatus() {
        try {
          const response = await fetch("/api/vggt/status");
          const status = await response.json();

          vggtEnabledCheckbox.checked = status.enabled;
          vggtIntervalSelect.value = status.inference_interval.toString();
          vggtEnabled = status.enabled;

          if (!status.loaded) {
            vggtStatusEl.textContent = "Not loaded";
            vggtStatusEl.style.color = "#ff5555";
            vggtEnabledCheckbox.disabled = true;
          } else if (status.enabled) {
            vggtStatusEl.textContent = "Active";
            vggtStatusEl.style.color = "#00ff88";
          } else {
            vggtStatusEl.textContent = "Off";
            vggtStatusEl.style.color = "#888";
          }

          console.log("[VGGT] Status loaded:", status);
        } catch (error) {
          console.error("[VGGT] Failed to load status:", error);
        }
      }

      // Load available cameras
      async function loadCameras() {
        try {
          const response = await fetch("/api/cameras");
          return await response.json();
        } catch (error) {
          console.error("Failed to load cameras:", error);
          return [];
        }
      }

      // Create camera plane with video texture
      function createCameraPlane(cameraId, colorIndex) {
        const planeWidth = 0.3; // 30cm in scene units (meters)
        const planeHeight = 0.17; // Maintain 16:9 aspect ratio

        // Create plane geometry
        const geometry = new THREE.PlaneGeometry(planeWidth, planeHeight);

        // Create canvas for texture
        const canvas = document.createElement("canvas");
        canvas.width = 320;
        canvas.height = 180;
        const ctx = canvas.getContext("2d");

        // Initial placeholder
        ctx.fillStyle = "#1a1a25";
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        ctx.fillStyle = "#555566";
        ctx.font = "14px JetBrains Mono";
        ctx.textAlign = "center";
        ctx.fillText(`Camera ${cameraId}`, canvas.width / 2, canvas.height / 2);

        // Create texture
        const texture = new THREE.CanvasTexture(canvas);
        texture.minFilter = THREE.LinearFilter;
        texture.magFilter = THREE.LinearFilter;

        // Material
        const material = new THREE.MeshBasicMaterial({
          map: texture,
          side: THREE.DoubleSide,
        });

        // Mesh
        const plane = new THREE.Mesh(geometry, material);
        plane.userData = {
          cameraId: cameraId,
          canvas: canvas,
          ctx: ctx,
          texture: texture,
        };

        // Add border frame
        const borderGeometry = new THREE.EdgesGeometry(geometry);
        const borderMaterial = new THREE.LineBasicMaterial({
          color: CAMERA_COLORS[colorIndex % CAMERA_COLORS.length],
        });
        const border = new THREE.LineSegments(borderGeometry, borderMaterial);
        plane.add(border);

        return plane;
      }

      // Create camera frustum visualization
      function createCameraFrustum(cameraId, colorIndex) {
        const color = CAMERA_COLORS[colorIndex % CAMERA_COLORS.length];
        const frustumLength = 0.15;
        const frustumWidth = 0.08;
        const frustumHeight = 0.045;

        // Create frustum lines - pointing along -Z (Three.js camera convention)
        const points = [
          // Origin
          new THREE.Vector3(0, 0, 0),
          // Four corners of far plane (negative Z direction)
          new THREE.Vector3(-frustumWidth, -frustumHeight, -frustumLength),
          new THREE.Vector3(frustumWidth, -frustumHeight, -frustumLength),
          new THREE.Vector3(frustumWidth, frustumHeight, -frustumLength),
          new THREE.Vector3(-frustumWidth, frustumHeight, -frustumLength),
        ];

        const lineGeometry = new THREE.BufferGeometry();
        const linePositions = [
          // Lines from origin to corners
          0,
          0,
          0,
          points[1].x,
          points[1].y,
          points[1].z,
          0,
          0,
          0,
          points[2].x,
          points[2].y,
          points[2].z,
          0,
          0,
          0,
          points[3].x,
          points[3].y,
          points[3].z,
          0,
          0,
          0,
          points[4].x,
          points[4].y,
          points[4].z,
          // Rectangle at far plane
          points[1].x,
          points[1].y,
          points[1].z,
          points[2].x,
          points[2].y,
          points[2].z,
          points[2].x,
          points[2].y,
          points[2].z,
          points[3].x,
          points[3].y,
          points[3].z,
          points[3].x,
          points[3].y,
          points[3].z,
          points[4].x,
          points[4].y,
          points[4].z,
          points[4].x,
          points[4].y,
          points[4].z,
          points[1].x,
          points[1].y,
          points[1].z,
        ];

        lineGeometry.setAttribute(
          "position",
          new THREE.Float32BufferAttribute(linePositions, 3)
        );
        const lineMaterial = new THREE.LineBasicMaterial({
          color: color,
          opacity: 0.7,
          transparent: true,
        });
        const frustum = new THREE.LineSegments(lineGeometry, lineMaterial);

        // Camera body (small box)
        const bodyGeometry = new THREE.BoxGeometry(0.04, 0.03, 0.02);
        const bodyMaterial = new THREE.MeshBasicMaterial({ color: color });
        const body = new THREE.Mesh(bodyGeometry, bodyMaterial);
        body.position.z = 0.01;
        frustum.add(body);

        return frustum;
      }

      // Position camera in scene based on extrinsics
      function positionCamera(cameraId, plane, frustum) {
        const calibration = calibrationData[cameraId];
        if (!calibration || !calibration.extrinsics) {
          console.warn(`No extrinsics for camera ${cameraId}`);
          return;
        }

        const ext = calibration.extrinsics;

        // Extract rotation matrix R and translation vector t from 4x4 matrix
        // The extrinsics are camera-to-world transforms
        const R = [
          [ext[0][0], ext[0][1], ext[0][2]],
          [ext[1][0], ext[1][1], ext[1][2]],
          [ext[2][0], ext[2][1], ext[2][2]],
        ];
        const t = [ext[0][3], ext[1][3], ext[2][3]];

        // Convert from OpenCV to Three.js coordinate system:
        // OpenCV: X-right, Y-down, Z-forward
        // Three.js: X-right, Y-up, Z-backward
        const position = new THREE.Vector3(
          t[0],
          -t[1], // Flip Y
          -t[2] // Flip Z
        );

        // Use rotation from extrinsics
        // Convert rotation: R' = F * R * F where F = diag(1,-1,-1)
        const rotMatrix = new THREE.Matrix4();
        rotMatrix.set(
          R[0][0],
          -R[0][1],
          -R[0][2],
          0,
          -R[1][0],
          R[1][1],
          R[1][2],
          0,
          -R[2][0],
          R[2][1],
          R[2][2],
          0,
          0,
          0,
          0,
          1
        );
        const quaternion = new THREE.Quaternion();
        quaternion.setFromRotationMatrix(rotMatrix);

        // Position the frustum at camera location
        frustum.position.copy(position);
        frustum.quaternion.copy(quaternion);

        // Position plane in front of camera (along -Z in camera local space)
        const planeOffset = 0.15;
        const lookDir = new THREE.Vector3(0, 0, -1);
        lookDir.applyQuaternion(quaternion);

        plane.position.copy(position).addScaledVector(lookDir, planeOffset);
        plane.quaternion.copy(quaternion);

        console.log(
          `Camera ${cameraId} (#${calibration.number}) pos:`,
          position.toArray().map((v) => v.toFixed(3))
        );
      }

      // Create UI for camera list
      function createCameraListUI(cameras) {
        cameraListEl.innerHTML = "";

        cameras.forEach((camId, index) => {
          const item = document.createElement("div");
          item.className = "camera-item";
          item.dataset.cameraId = camId;

          const color = CAMERA_COLORS[index % CAMERA_COLORS.length];
          const calibration = calibrationData[camId];
          const camNumber = calibration ? calibration.number : index + 1;
          const isMaster = calibration && calibration.master;
          const hasYolo = calibration && calibration.yolo_enabled;

          let badges = "";
          if (isMaster) badges += " (Master)";
          if (hasYolo)
            badges +=
              ' <span style="color:#00ff88;font-weight:600;">YOLO</span>';

          item.innerHTML = `
            <div class="camera-color" style="background: #${color
              .toString(16)
              .padStart(6, "0")}"></div>
            <div class="camera-info">
              <div class="camera-id">${camId}</div>
              <div class="camera-number">Camera #${camNumber}${badges}</div>
            </div>
          `;

          item.addEventListener("click", () => focusOnCamera(camId));
          cameraListEl.appendChild(item);
        });
      }

      // Focus view on specific camera
      function focusOnCamera(cameraId) {
        const plane = cameraPlanes[cameraId];
        if (!plane) return;

        // Animate camera to look at plane
        const targetPos = plane.position.clone();

        // Calculate good viewing position
        const direction = new THREE.Vector3(0, 0, 1);
        direction.applyQuaternion(plane.quaternion);

        const viewPos = targetPos.clone().add(direction.multiplyScalar(1.5));
        viewPos.y += 0.5;

        // Update controls target
        controls.target.copy(targetPos);
        camera.position.copy(viewPos);

        // Update selected state in UI
        document.querySelectorAll(".camera-item").forEach((item) => {
          item.classList.toggle("selected", item.dataset.cameraId === cameraId);
        });
      }

      // Start streaming frames
      async function startStreaming() {
        if (streaming) return;

        // Tell the server to start processing frames
        try {
          const response = await fetch("/api/stream/start", { method: "POST" });
          const result = await response.json();
          console.log("[Stream] Server started:", result);
        } catch (error) {
          console.error("[Stream] Failed to start server streaming:", error);
          return;
        }

        streaming = true;

        // Start pose polling for real-time tool position updates
        startPosePolling();

        // Start VGGT polling if enabled
        if (vggtEnabled) {
          startVGGTPolling();
        }

        Object.keys(cameraPlanes).forEach((cameraId) => {
          const plane = cameraPlanes[cameraId];
          const { canvas, ctx, texture } = plane.userData;

          // Create image element for loading frames
          const img = new Image();
          img.crossOrigin = "anonymous";

          const updateFrame = () => {
            if (!streaming) return;

            // Add timestamp to avoid caching
            img.src = `/api/frame/${cameraId}?t=${Date.now()}`;
          };

          img.onload = () => {
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
            texture.needsUpdate = true;

            if (streaming) {
              // Request next frame
              setTimeout(updateFrame, 66); // ~15 FPS
            }
          };

          img.onerror = () => {
            if (streaming) {
              setTimeout(updateFrame, 500);
            }
          };

          // Start loading frames
          updateFrame();
        });

        startBtn.textContent = "Stop Streams";
        statusDot.classList.add("active");
        statusText.textContent = "Streaming";
      }

      // Stop streaming
      async function stopStreaming() {
        streaming = false;

        // Stop pose polling
        stopPosePolling();

        // Stop VGGT polling
        stopVGGTPolling();

        // Tell the server to stop processing frames
        try {
          const response = await fetch("/api/stream/stop", { method: "POST" });
          const result = await response.json();
          console.log("[Stream] Server stopped:", result);
        } catch (error) {
          console.error("[Stream] Failed to stop server streaming:", error);
        }

        startBtn.textContent = "Start Streams";
        statusDot.classList.remove("active");
        statusText.textContent = "Paused";
      }

      // Animation loop
      function animate() {
        requestAnimationFrame(animate);

        controls.update();
        renderer.render(scene, camera);
      }

      // Initialize everything
      async function init() {
        // Initialize Three.js
        initScene();

        // Load calibration first (needed for GLB positioning)
        await loadCalibration();
        availableCameras = await loadCameras();

        console.log("Available cameras:", availableCameras);

        // Load GLB scene model (after calibration so we can position it)
        try {
          await loadGLBScene();
        } catch (error) {
          console.error("Failed to load GLB scene, continuing anyway:", error);
        }

        // Load all DOPE object models (tool, case, etc.)
        try {
          await loadAllDopeObjects();
        } catch (error) {
          console.error(
            "Failed to load DOPE object models, continuing anyway:",
            error
          );
        }

        // Initialize VGGT point cloud visualization
        initVGGTPointCloud();

        // Load VGGT status from server
        await loadVGGTStatus();

        // Create camera planes and frustums
        availableCameras.forEach((cameraId, index) => {
          // Create plane with video texture
          const plane = createCameraPlane(cameraId, index);
          cameraPlanes[cameraId] = plane;
          scene.add(plane);

          // Create frustum visualization
          const frustum = createCameraFrustum(cameraId, index);
          cameraFrustums[cameraId] = frustum;
          scene.add(frustum);

          // Position based on extrinsics
          positionCamera(cameraId, plane, frustum, false);
        });

        // Update UI
        cameraCountEl.textContent = availableCameras.length.toString();
        createCameraListUI(availableCameras);

        // Event listeners
        startBtn.addEventListener("click", () => {
          if (streaming) {
            stopStreaming();
          } else {
            startStreaming();
          }
        });

        // GLB event listener
        glbEnabledCheckbox.addEventListener("change", (e) => {
          glbVisible = e.target.checked;
          if (glbSceneModel) {
            glbSceneModel.visible = glbVisible;
            glbStatusEl.textContent = glbVisible ? "Visible" : "Hidden";
            glbStatusEl.style.color = glbVisible ? "#00ff88" : "#888";
            console.log(`[GLB] Scene ${glbVisible ? "shown" : "hidden"}`);
          }
        });

        // VGGT event listeners
        vggtEnabledCheckbox.addEventListener("change", (e) => {
          setVGGTEnabled(e.target.checked);
        });

        vggtIntervalSelect.addEventListener("change", (e) => {
          setVGGTInterval(e.target.value);
        });

        // Hide loading overlay
        loadingOverlay.classList.add("hidden");
        statusText.textContent = "Ready";

        // Start animation
        animate();
      }

      // Start
      init().catch(console.error);
    </script>
  </body>
</html>
