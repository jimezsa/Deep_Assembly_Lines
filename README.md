# Human Activity Understanding - Screw Assembly Tracking

![GitHub Repo Banner](project_image.png)

3D scene visualization system that tracks a Batteries Screw assembly task using multi-camera recordings, DOPE pose estimation, YOLOv11 segmentation and VGGT for 3D Scene reconstruction

## Demo

![x5Demo](x5demo.gif)

## Installation

### 1. Create Conda Environment

```bash
conda create -n HAUP python=3.10 -y
conda activate HAUP
```

### 2. Install PyTorch

**For macOS (Apple Silicon - M1/M2/M3):**

```bash
conda install pytorch::pytorch torchvision torchaudio -c pytorch -y
```

**For NVIDIA GPU (CUDA 12.1):**

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

## Run

```bash
python 3d_scene/3dscene.py
```

Open your browser at **http://localhost:8085**

## ğŸ“ Project Structure

```
â”œâ”€â”€ 3d_scene/                    # Main application
â”‚   â”œâ”€â”€ 3dscene.py              # Backend server (aiohttp)
â”‚   â”œâ”€â”€ web_interface.html      # 3D visualization frontend (Three.js)
â”‚   â”œâ”€â”€ screw_sequence_tracker.py   # Screw sequence state machine
â”‚   â”œâ”€â”€ sequence_from_distance_tool.py  # CLI monitoring tool
â”‚   â”œâ”€â”€ distance_tool_screw.py  # Distance API client
â”‚   â”œâ”€â”€ dope_inference.py       # DOPE 6D pose estimation
â”‚   â”œâ”€â”€ yolo_inference.py       # YOLOv11 segmentation
â”‚   â”œâ”€â”€ vggt_inference.py       # 3D point cloud reconstruction
â”‚   â”œâ”€â”€ battery_fsm_module.py   # Battery tracking state machine (YOLO-based)
â”‚   â””â”€â”€ config/                 # Camera calibrations & DOPE config
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ recording_1-12/         # Multi-camera recordings (8 cameras each)
â”‚   â”œâ”€â”€ scanned_objects/        # 3D models (case, e-screwdriver)
â”‚   â””â”€â”€ cams_calibrations.yml   # Camera calibration data
â”‚
â”œâ”€â”€ weights/                    # Model weights
â”‚   â”œâ”€â”€ dope_tool.pth          # DOPE weights for screwdriver
â”‚   â”œâ”€â”€ dope_case.pth          # DOPE weights for case
â”‚   â””â”€â”€ model.pt               # YOLOv11 finetuned weights
â”‚
â”œâ”€â”€ frameworks/                 # External frameworks
â”‚   â”œâ”€â”€ dope/                  # DOPE implementation
â”‚   â””â”€â”€ vggt/                  # VGGT point cloud
â”‚
â””â”€â”€ yolov11_finetuned/         # YOLOv11 training & testing
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

This project uses the following research works:

- **DOPE (Deep Object Pose Estimation)** - 6D pose estimation for object detection
  https://github.com/NVlabs/Deep_Object_Pose

- **VGGT (Visual Geometry Grounded Transformer)** - 3D scene reconstruction
  https://vgg-t.github.io/

- **YOLO (You Only Look Once, by Ultralytics)** - state-of-the-art real-time object detection
  https://github.com/ultralytics/ultralytics

---

**Course:** Practical Course - Human Activity Understanding  
**Institution:** Technical University of Munich (TUM)
